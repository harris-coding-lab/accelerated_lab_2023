---
title: "Accelerated Coding Lab 5: Data manipulation with `dplyr`"
author: "Ari Anisfeld"
date: "Summer 2023"
urlcolor: blue
output:
  pdf_document:
    toc: yes
---

```{r setup, include = FALSE}
library(tidyverse)
library(readxl)
student_loan_debt <- read_csv("data/student_loan_debt.csv")
population <- read_csv("data/population.csv")
```


Complete the following lab in an Rmd. In your `setup` chunk, load `tidyverse` and `readxl`. 

<!-- TODO: UPDATE FILE LINK!!! -->

We'll work with the following [`data set`](https://github.com/harris-coding-lab/accelerated_lab_2022/raw/main/Labs%20(accelerated)/Lab%205/data/area_report_by_year.xlsx?raw=true). Download it and put the data in the appropriate folder. The data comes from the [NY Fed databank](https://www.newyorkfed.org/microeconomics/databank.html)



# Warm up

1.

  a. In class, you learned about `head()`. What if you wanted to get the tail end of your data instead?
  b. Use vector coercion^[`as.___()`] to make `c("1", "3", "4") + 4`  produce `c(5, 7, 8)`.
  c. Both code snippets produces the same result  `1:4 %in% c(1, -4) ` and `1:4 == c(1, -4)`.  But they are not logically equivalent! Provide a counterexample.
  d. Are the following logically equivalent? `1:4 %in% c(1, -4)` and `1:4 == 1 | 1:4 == -4` If yes, why? If no, provide a counter example.
  
  
2. Recall our `dplyr` verbs. 

- mutate() - filter() - select() - arrange() - summarize()

What is the purpose of each function?


3. For the next few problems  you'll translate base R code to `dplyr` code.
We want to have identical output. We use `midwest`--the data set is avaiable when you load `tidyverse`.

a. 
```{r}
low_density_counties <- midwest[midwest$popdensity < 120, 
                       c("county", "state", "poptotal", "area")]

low_density_counties[order(low_density_counties$poptotal,
                           decreasing = TRUE), ]
```

b. We will analyze poverty data. Notice that some counties are missing the poverty status for a large portion of the population. Missing data can cause biased estimates if the data is not missing at random. 

To provide conservative bounds on our estimates, consider the extremes. Either **all** the non-responses have incomes below the poverty line or **none** do.

Write the following base R code as tidyverse code. 

```{r chunk}
midwest$poverty_unknown <- 100 - midwest$percpovertyknown
midwest$low_estimate <- round(midwest$percbelowpoverty)
midwest$high_estimate <- round(midwest$percbelowpoverty + midwest$poverty_unknown)

out <- midwest[midwest$high_estimate > 35, 
        c("county", "state", "low_estimate", "high_estimate")]

out
```
  
Before moving on, knit to see how the table looks!^[There are a number of functions/packages designed to make tables prettier. `knitr::kable` is a simple go-to.<!-- (But there are a lot of other options out there: https://rfortherestofus.com/2019/11/how-to-make-beautiful-tables-in-r/)-->}] Knitting early and often will save you stress at deadlines!


c. **Challenge:** You look at the data again and realize the previous code is not correct. The percent below poverty and the percent of unknown/known poverty status are based on different populations! 

Compare: 

$$ \text{Perc. known status} = \frac{\text{N known status}}{\text{Total population}}$$
 with
 
$$  \text{Perc. below poverty} = \frac{\text{N below poverty}}{\text{N known status}} $$

After finishing the rest of the lab, come back and try to code this up. The result should match our table.^[To develop intuition, consider a county with 1000 people with 90\% known poverty status. Thus, `N known status = 1000 * .9 = 900` and 100 without a known status. Further, let the perc below poverty be 10\%. This implies `N below poverty = 900 * .1 = 90`.  Now, how do we bound the poverty rate? Consider 100 people with unknown status. At the extreme, all of them are below the poverty line and 190 residents below the line *or* zero of them are below the poverty line and 90 residents are below the poverty line. Thus the bounds are $\frac{90}{1000} - \frac{190}{1000}$$ or 9 to  19 percent. With the erroneous method, we'd say the range was between 10 and 20 percent. ]

```{r, echo = FALSE}
midwest %>%
  mutate(n_known_status = poppovertyknown,
         n_below_poverty = n_known_status * percbelowpoverty / 100,
         n_unknown_status = poptotal - n_known_status,
         low_estimate = 100 * n_below_poverty / poptotal,
         high_estimate = 100 * (n_below_poverty + n_unknown_status) / poptotal) %>%
  filter(high_estimate >= 35) %>%
  select(county, state, low_estimate, high_estimate) %>%
  mutate_if(is.numeric, round)
```


d. Convert these to tidyverse code to make a summary of the data. 

```{r}
data.frame(county_mean_perc_below_poverty = round(mean(midwest$percbelowpoverty), 1),
county_mean_perc_below_child_poverty = round(mean(midwest$percchildbelowpovert), 1))


```

e. Notice the means above are the means of *county* poverty rates, which is not the same as the poverty rate for the population in our data.^[To see why, imagine a state with one highly populated county with a high poverty rate (50 percent) and 99 counties each with 1 person whose income is above the poverty. The average of county poverty rates will be small (.5 percent), while the state poverty rate might could be close to 50 percent.] Write code to calculate the poverty rate for the `midwest` using the formula for "$\text{Perc. below poverty}$" shown above.^[Hint: notice the numerator and denominator are both sums.]

```{r, echo = FALSE}
midwest %>%
  mutate(n_below_poverty =  poppovertyknown * percbelowpoverty / 100) %>%
  summarize(n_below_poverty = sum(n_below_poverty),
            n_poverty_known = sum(poppovertyknown),
            perc_below_poverty = round(100 * n_below_poverty / n_poverty_known, 1))
```




# Analyzing Student Loan Debt

1. Load data. Mine is stored in the `data` folder inside the folder with my Rmd.

```{r, message = FALSE, eval = FALSE}
fed_data <- read_xlsx("data/area_report_by_year.xlsx")
```

*Remark:* Recall Rmds know what folder they are in and make it the working directory. So, R looks for a `data` folder in the working directory and then for the file in that folder. You could also give R an *absolute* file path, such as: `"/Users/username/Coding Lab/labs/data/area_report_by_year.xlsx"`, but your code would be harder to share.

2. Look at `fed_data` and notice there are some issues!  Run the code below to fix the issues. We want you to see what data prep looks like and will explain this step-by-step!


```{r clean, eval=FALSE}
library(tidyverse)
library(readxl)

# CAREFUL with copy paste from pdfs. The quotes "" might change!
# We provide an R script with this code on canvas if you are having trouble.
# (And links to the resulting csv)
student_loan_debt <- 
  read_xlsx("data/area_report_by_year.xlsx", 
            sheet = "studentloan", 
            skip = 3) %>%
    filter(state != "allUS")  %>%
    pivot_longer(cols = -state, 
                 names_to = "year", 
                 values_to = "per_capita_student_debt") |>
    mutate(year = str_sub(year, 4, 7),
           year = as.numeric(year))

write_csv(student_loan_debt, "data/student_loan_debt.csv")
```


## Data Cleaning: Step by step 
 
**1: read what we need**
```{r clean1, eval=FALSE}
student_loan_debt <- read_xlsx("data/area_report_by_year.xlsx", 
                               sheet = "studentloan", 
                               skip = 3) 
```

We tell `read_xlsx` to specify the `sheet` in the Excel workbook we want to read, and we `skip` the first 3 rows in the sheet, because the data we're interested in starts on line 4.

![](images/02_wide.jpg){width=30%}

**2: filter out unwanted data**
```{r clean2, eval=FALSE}
filter(state != "allUS")
```

We **filter out rows of data** that are for the entire US, leaving only rows that refer to states.


**3: tidy our data**

```{r clean3, eval=FALSE}
pivot_longer(cols = -state, names_to = "year", values_to = "per_capita_student_debt") 
```

 We **convert the data from a wide to a long format**, so that `year` is a variable and `per_capita_student_debt` is also a variable. This will makes analysis easier.^[Read more about [tidy data](https://r4ds.had.co.nz/tidy-data.html#introduction-6) in R for Data Science.)]

![](images/03_long.jpg){width=30%}

**4: clean up year**
```{r clean4, eval=FALSE}
mutate(year = str_sub(year, 4, 7),
       year = as.numeric(year))
```

We use **string manipulation** to modify the `year` column, and then **convert the type** of the column.

![](images/04_final.jpg){width=30%}

5. **Write the data for future use**

```{r clean5, eval=FALSE}
write_csv(student_loan_debt, "data/student_loan_debt.csv")
```

We write the cleaned data to a CSV (comma-separated variables file).



Try running this code locally on your computer step-by-step! The csv is also available [here](https://raw.githubusercontent.com/harris-coding-lab/accelerated_lab_2022/main/Labs%20(accelerated)/Lab%205/data/student_loan_debt.csv) and you can load by reading the csv directly from the url.


## Exploratory Data Analysis

**Note**: `student_loan_debt` can be long to type, so use **Tab-Autocomplete**. Once you start typing the variable in the function, press **Tab** and wait for the variable name to automatically pop up. Press **Tab** again or **Enter** to fill in `student_loan_debt` (or click on it).


### Arranging Data

We can use the `arrange()` function from `dplyr` to sort the student loan data. The syntax is `arrange(data, variables)` or `data |>arrange(variables)`.  

- What state or territory had the lowest per capita debt in our data? 
- How much was the lowest per capita debt and what year did it occur?
- How much was the highest per capita debt?
- What years does this data cover?

After ensuring `arrange` works as you expect, pipe the output to `head(1)` to only print the first row to answer the questions.

```{r arrange, include = FALSE}
student_loan_debt %>%
  arrange(per_capita_student_debt) %>%
  head(1)

student_loan_debt %>%
  arrange(desc(per_capita_student_debt))  %>%
  head(1)

student_loan_debt %>%
  arrange(year) %>%
  head(1)

student_loan_debt %>%
  arrange(desc(year)) %>%
  head(1)
# sometimes there's a more direct solution than sorting!
range(student_loan_debt$year)
summary(student_loan_debt$year)  
student_loan_debt |>
  summarize(earliest = min(year), 
            latest = max(year))
```


### Filtering Data

```{r filter, eval = FALSE}
# filter student_loan_debt so we have 
# rows with per_capita_student_debt less than 800
filter(student_loan_debt, per_capita_student_debt < 800)
```

1. Write a `filter` statement to get all states with an average per capita student debt of 10000 or higher in the year 2020 or higher. Recall, you can combine multiple criteria - just add a comma and another filtering criteria! This is equivalent to the logical *AND*.^[**Hint:** Your code should look like this: `filter(data, condition1, condition2)` or `data |> filter(condition1, condition2)`]

```{r filter2, include = FALSE}
student_loan_debt |>
  filter(year >= 2020, per_capita_student_debt >= 10000)
```


2.  Get the rows for Illinois (IL) since 2012 *OR* for California (CA) from 2013 on. (The resulting data frame should have 19 rows).

```{r filter3, include = FALSE}
student_loan_debt %>%
  filter(state == "IL" & year >= 2012 |
         state == "CA" & year >= 2013)
```

3. Your friend wrote the following code and decide there are no missing values. But you know there are!

```{r, echo = TRUE}
# your friend's code
student_loan_debt |>
  filter(per_capita_student_debt == NA)

# your code
student_loan_debt %>%
  filter(state == "PR", year == 2021) 
```

Explain the discrepancy and then write code to find all the rows with missing data! 

```{r filter-na, include = FALSE}
filter(student_loan_debt, is.na(per_capita_student_debt))
```


### Summarizing data

1. Collect the data for the year 2016 and use summarize to calculate the min, max, mean and median of `per_capita_student_debt`.

2. Repeat the exercise for 2021. 


```{r, include=FALSE}
student_loan_debt %>%
  filter(year == 2016) %>%
  summarize(min = min(per_capita_student_debt),
            mean = mean(per_capita_student_debt),
            median = median(per_capita_student_debt),
            max = max(per_capita_student_debt),)
```

```{r, include=FALSE}
student_loan_debt %>%
  filter(year == 2021) %>%
  summarize(min = min(per_capita_student_debt),
            mean = mean(per_capita_student_debt),
            median = median(per_capita_student_debt),
            max = max(per_capita_student_debt))
```

3. Notice anything strange about the year 2021? We get `NA` for everything! Recall `NA`s are contagious. Let's make sure we understand how to proceed with a simple example.  

```{r group5}
# Adjust the call to remove the `NA` and return a mean of 2.
mean(c(NA, 1, 2, 3))
```

4. What is the mean per capita debt in 2021 if we exclude NAs? 

```{r, include = FALSE}
student_loan_debt %>%
  group_by(year) %>%
  # filter(year == 2021) %>%
  summarize(min = min(per_capita_student_debt, na.rm=TRUE),
            mean = mean(per_capita_student_debt, na.rm=TRUE),
            median = median(per_capita_student_debt, na.rm=TRUE),
            max = max(per_capita_student_debt, na.rm=TRUE))
```


### Bringing in population data

We saw that DC has the highest level of per-capita student loan debt. However, you might wonder how much *total* student debt is held by the capital's residents. To tackle this, we need a population dataset. Fortunately, in the `area_report_by_year.xlsx` there is a sheet called "population", which refers to the number of individuals over 18 years of age who have a credit report with Equifax.

1. The data is stored in exactly the same way as the student loan data.This implies you can reuse the code from before with a few (precisely 2) modifications. Copy and paste your code from before and make the modifications. The  result looks like this:^[If you're having trouble. Download our csv, here's the [link for population.csv](https://raw.githubusercontent.com/harris-coding-lab/accelerated_lab_2022/main/Labs%20(accelerated)/Lab%205/data/population.csv)] 

![](images/05_pop.jpg){width=30%}

2. To join the two data sets, use the following code.

```{r join}
joined_data <- 
  student_loan_debt |>
    left_join(population, by = c("state", "year"))
```

We link the two dataframes to each other when they have the same `state` and `year` values.^[The base R function is `merge()`.] 

The joined data looks like this (note the extra column):

![](images/06_joined.jpg){width=30%}

### How much student debt is held in each state?

1. Now, we need to create a new column! What tidyverse verb do you use? 

1. Calculate the total student debt in a state and assign the output to the name `total_student_debt_data`.

```{r reweight1, include = FALSE}
total_student_debt_data <- 
  joined_data |>
    mutate(total_student_debt = population * per_capita_student_debt,
           total_student_debt = round(total_student_debt/1e9, 1))
```

Take a look at the results.

2. The values are hard to read because they're such big numbers. Adjust the values so that they're in billions of dollars.^[e.g. 15230000000 becomes 15.2 (billion)]
Go back to where you originally created `total_student_debt_data` and add the adjustment to that code.

```{r, eval = FALSE}
#  for example my code looks like 
total_student_debt_data <- 
  joined_data |>
    mutate(total_student_debt = _______________, # first multiply the columns
           total_student_debt = _______________) # then adjust the column so 
                                                 # it's easier to communicate

```

*Remark:* Keep code that does similar stuff together in the script/Rmd. 


3. Let's add a ranking column to see where DC falls. The built-in `rank()` function will come in handy. Let's explore it first. 

```{r, eval = FALSE}
y <- c(5, 7, 7, 9, 1)

exploring_rank <- 
tibble(y = y,
       rank = rank(y))

exploring_rank |>arrange(y)
```

What is `rank()` default method for dealing with ties? Add columns to your example where we use different tie methods. (For help `?rank`!)

4. Focus on 2021, where is DC in this ranking? (Add a column with the rank number!) You may have gotten rank = 10, that's not exactly what you want ...^[You want bigger numbers to have lower ranks; you can use the same function we use with `arrange()` to make it happen.]

```{r, include = FALSE}
total_student_debt_data %>%
  filter(year == 2021) %>%
  mutate(rank = row_number(desc(total_student_debt))) |>
  filter(state == "DC") 
```

5. We often want to add `rank(x, ties.method = "first")` to data. `dplyr` has a function `row_number()` which might be easier to remember than `rank(x, ties.method = "first")`.

In your previous answer, swap in `row_number()`.

## Exploring with visualization

We'll continue to tease data visualization methods in labs, and go over them in detail soon.

1. Make a plot showing the top 4 states in terms of total debt over time. Prepare the data and then make the plot.

```{r, eval = FALSE}
# you should get the same plot as we do below.
  ggplot(data = __________, 
         aes(x = year, 
             y = total_student_debt,
            color = state)) + 
  geom_line() +
  labs(y = "Total student debt in billions")
```


```{r, echo = FALSE, out.width=300}
total_student_debt_data %>%
  filter(state %in% c("CA", "TX", "FL", "NY")) %>%
  ggplot(aes(x = year, 
             y = total_student_debt,
              color = state)) + 
  geom_line() +
  labs(y = "Total student debt in billions")
```

2. Notice that New York changes it's ranking over time. This can be driven by either a slowing population growth *or* a decline in per capita borrowing (or both). Copy and paste the ggplot code and change the `y` variable to make two plots to examine those trends. Change the y axis label as well.


3. Finally, if you have time, go back and try the challenge problem from the warm-up.



## Appendix: Reading population data

Here's the code used to clean the population data:

```{r cleanpop, eval=FALSE}

# Rather than copy and paste this code.
# Copy your earlier code and make two adjustments

population <- 
  read_xlsx("data/area_report_by_year.xlsx", 
            sheet = "population",  # Change the sheet
            skip = 3)  %>%
  filter(state != "allUS") %>%
  pivot_longer(cols = -state, 
               names_to = "year", 
               values_to = "population") |> # change the name of the column.
  mutate(year = str_sub(year, 4, 7),
         year = as.numeric(year))

write_csv(population, "data/population.csv")
```